{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Wlx2zPagockh",
        "outputId": "60aaba0b-3072-4679-8dce-1a65dc6e5851"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c51aab38-6420-48b5-97e7-418f6a8f3a67\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c51aab38-6420-48b5-97e7-418f6a8f3a67\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nano_ai_final_aug.csv to nano_ai_final_aug.csv\n",
            "   Nano_Silica (%)       W/C  Plasticizer  Cement (kg/m³)  Fine_Agg (kg/m³)  \\\n",
            "0         3.170000  0.480000     0.710000      447.800000        527.100000   \n",
            "1         1.452613  0.693848     0.286133      362.380948        638.629896   \n",
            "2         2.688229  0.580481     1.013763      480.496924        767.253862   \n",
            "3         4.192975  0.449628     0.175303      443.493451        688.191828   \n",
            "4         1.242139  0.391894     0.536623      449.401746        725.742176   \n",
            "\n",
            "   Coarse_Agg (kg/m³)  Strength (N/mm²)  \n",
            "0         1035.500000         26.010000  \n",
            "1         1169.643246         28.598149  \n",
            "2         1122.439172         23.254848  \n",
            "3         1142.478188         26.412861  \n",
            "4         1397.710087         30.661000  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "df = pd.read_csv(io.BytesIO(uploaded['nano_ai_final_aug.csv']))\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4KEt2pvo1lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check column names\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC20b0dtpBc7",
        "outputId": "d6831dcf-052a-48e8-fd4d-fbfcdd669a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Nano_Silica (%)', 'W/C', 'Plasticizer', 'Cement (kg/m³)',\n",
            "       'Fine_Agg (kg/m³)', 'Coarse_Agg (kg/m³)', 'Strength (N/mm²)'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\n",
        "X = df.drop(columns=['Strength (N/mm²)']).values\n",
        "\n",
        "# Target\n",
        "y = df['Strength (N/mm²)'].values\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5bG0xZ5pGw7",
        "outputId": "cdf8d10b-a623-4bcd-f147-52ff3f25fdb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (952, 6)\n",
            "Target shape: (952,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for RNN/LSTM: (samples, timesteps, features)\n",
        "X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_rnn = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "print(\"X_train_rnn shape:\", X_train_rnn.shape)\n",
        "print(\"X_test_rnn shape:\", X_test_rnn.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgPq_ulnpL1p",
        "outputId": "48ab4235-88f1-46cd-c9c9-89973a63f7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_rnn shape: (761, 1, 6)\n",
            "X_test_rnn shape: (191, 1, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "# ----------------------\n",
        "# 1️⃣ Pure RNN\n",
        "# ----------------------\n",
        "rnn_model = Sequential([\n",
        "    Input(shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
        "    SimpleRNN(64, activation='tanh'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "rnn_model.compile(optimizer=Adam(0.001), loss='mse', metrics=['mae'])\n",
        "rnn_model.fit(X_train_rnn, y_train, validation_data=(X_test_rnn, y_test),\n",
        "              epochs=200, batch_size=32, callbacks=[early_stop], verbose=0)\n",
        "\n",
        "y_pred_rnn = rnn_model.predict(X_test_rnn)\n",
        "r2_rnn = r2_score(y_test, y_pred_rnn)\n",
        "print(\"Pure RNN R² Score:\", r2_rnn)\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "# 2️⃣ LSTM RNN\n",
        "# ----------------------\n",
        "lstm_model = Sequential([\n",
        "    Input(shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
        "    LSTM(64, activation='tanh'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer=Adam(0.001), loss='mse', metrics=['mae'])\n",
        "lstm_model.fit(X_train_rnn, y_train, validation_data=(X_test_rnn, y_test),\n",
        "               epochs=200, batch_size=32, callbacks=[early_stop], verbose=0)\n",
        "\n",
        "y_pred_lstm = lstm_model.predict(X_test_rnn)\n",
        "r2_lstm = r2_score(y_test, y_pred_lstm)\n",
        "print(\"LSTM RNN R² Score:\", r2_lstm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1eOFWA-po3N",
        "outputId": "49e072df-3d21-4acc-9daf-4e36b5884a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Pure RNN R² Score: 0.45605500427216916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3c6d481120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "LSTM RNN R² Score: 0.545050899569756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "UhjmN2ASsO78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_rnn  = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n"
      ],
      "metadata": {
        "id": "7jQPPW0_sRlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n"
      ],
      "metadata": {
        "id": "4815EQBasW4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Pure RNN example\n",
        "rnn_model = Sequential([\n",
        "    SimpleRNN(64, activation='tanh', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "rnn_model.compile(optimizer=Adam(0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# LSTM example\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, activation='tanh', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm_model.compile(optimizer=Adam(0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixVetQeBsYmF",
        "outputId": "a32fb97b-6709-4f8f-d3c4-cd03c836223e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = rnn_model.fit(X_train_rnn, y_train,\n",
        "                        validation_data=(X_test_rnn, y_test),\n",
        "                        epochs=200, batch_size=32, callbacks=[early_stop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAEfWuCwscZE",
        "outputId": "3bbf08b1-500e-4d07-bb63-9315e8c3cf52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 675.5500 - mae: 25.7985 - val_loss: 630.8401 - val_mae: 24.9399\n",
            "Epoch 2/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 635.5869 - mae: 25.0124 - val_loss: 594.1142 - val_mae: 24.1898\n",
            "Epoch 3/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 598.7742 - mae: 24.2616 - val_loss: 550.7097 - val_mae: 23.2701\n",
            "Epoch 4/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 552.5092 - mae: 23.2803 - val_loss: 493.7808 - val_mae: 21.9996\n",
            "Epoch 5/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 491.9816 - mae: 21.9229 - val_loss: 420.9966 - val_mae: 20.2500\n",
            "Epoch 6/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 415.5284 - mae: 20.0659 - val_loss: 333.4238 - val_mae: 17.9069\n",
            "Epoch 7/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 325.4215 - mae: 17.6097 - val_loss: 237.8014 - val_mae: 14.9227\n",
            "Epoch 8/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 229.5388 - mae: 14.5290 - val_loss: 147.1060 - val_mae: 11.4036\n",
            "Epoch 9/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 140.5031 - mae: 10.9573 - val_loss: 75.5272 - val_mae: 7.7661\n",
            "Epoch 10/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 71.5400 - mae: 7.3087 - val_loss: 31.6900 - val_mae: 4.6312\n",
            "Epoch 11/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5058 - mae: 4.4230 - val_loss: 14.4527 - val_mae: 2.9999\n",
            "Epoch 12/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15.1715 - mae: 3.1432 - val_loss: 11.1729 - val_mae: 2.6794\n",
            "Epoch 13/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.0948 - mae: 2.8319 - val_loss: 10.7091 - val_mae: 2.6338\n",
            "Epoch 14/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.4582 - mae: 2.7610 - val_loss: 10.3515 - val_mae: 2.6016\n",
            "Epoch 15/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.1084 - mae: 2.7299 - val_loss: 10.0194 - val_mae: 2.5702\n",
            "Epoch 16/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.8305 - mae: 2.7085 - val_loss: 9.7500 - val_mae: 2.5458\n",
            "Epoch 17/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.5928 - mae: 2.6906 - val_loss: 9.5391 - val_mae: 2.5267\n",
            "Epoch 18/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.3850 - mae: 2.6728 - val_loss: 9.3652 - val_mae: 2.5117\n",
            "Epoch 19/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.2089 - mae: 2.6570 - val_loss: 9.2240 - val_mae: 2.4999\n",
            "Epoch 20/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.0617 - mae: 2.6432 - val_loss: 9.1090 - val_mae: 2.4897\n",
            "Epoch 21/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9331 - mae: 2.6308 - val_loss: 9.0095 - val_mae: 2.4817\n",
            "Epoch 22/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8201 - mae: 2.6189 - val_loss: 8.9113 - val_mae: 2.4725\n",
            "Epoch 23/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7210 - mae: 2.6080 - val_loss: 8.8249 - val_mae: 2.4630\n",
            "Epoch 24/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6254 - mae: 2.5979 - val_loss: 8.7418 - val_mae: 2.4532\n",
            "Epoch 25/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5344 - mae: 2.5870 - val_loss: 8.6646 - val_mae: 2.4439\n",
            "Epoch 26/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4481 - mae: 2.5761 - val_loss: 8.5941 - val_mae: 2.4351\n",
            "Epoch 27/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3660 - mae: 2.5663 - val_loss: 8.5275 - val_mae: 2.4265\n",
            "Epoch 28/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2852 - mae: 2.5563 - val_loss: 8.4673 - val_mae: 2.4182\n",
            "Epoch 29/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2074 - mae: 2.5462 - val_loss: 8.4094 - val_mae: 2.4100\n",
            "Epoch 30/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1317 - mae: 2.5359 - val_loss: 8.3556 - val_mae: 2.4020\n",
            "Epoch 31/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.0566 - mae: 2.5254 - val_loss: 8.2979 - val_mae: 2.3934\n",
            "Epoch 32/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9821 - mae: 2.5146 - val_loss: 8.2418 - val_mae: 2.3853\n",
            "Epoch 33/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9108 - mae: 2.5041 - val_loss: 8.1881 - val_mae: 2.3777\n",
            "Epoch 34/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.8425 - mae: 2.4939 - val_loss: 8.1401 - val_mae: 2.3711\n",
            "Epoch 35/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7732 - mae: 2.4835 - val_loss: 8.0925 - val_mae: 2.3646\n",
            "Epoch 36/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7070 - mae: 2.4730 - val_loss: 8.0456 - val_mae: 2.3580\n",
            "Epoch 37/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6431 - mae: 2.4625 - val_loss: 8.0022 - val_mae: 2.3515\n",
            "Epoch 38/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5784 - mae: 2.4529 - val_loss: 7.9609 - val_mae: 2.3455\n",
            "Epoch 39/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5151 - mae: 2.4427 - val_loss: 7.9154 - val_mae: 2.3387\n",
            "Epoch 40/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4539 - mae: 2.4337 - val_loss: 7.8772 - val_mae: 2.3328\n",
            "Epoch 41/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3927 - mae: 2.4247 - val_loss: 7.8385 - val_mae: 2.3271\n",
            "Epoch 42/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3353 - mae: 2.4163 - val_loss: 7.7997 - val_mae: 2.3211\n",
            "Epoch 43/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2780 - mae: 2.4082 - val_loss: 7.7649 - val_mae: 2.3160\n",
            "Epoch 44/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.2235 - mae: 2.4000 - val_loss: 7.7329 - val_mae: 2.3111\n",
            "Epoch 45/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1669 - mae: 2.3914 - val_loss: 7.7003 - val_mae: 2.3066\n",
            "Epoch 46/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.1163 - mae: 2.3836 - val_loss: 7.6720 - val_mae: 2.3029\n",
            "Epoch 47/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.0607 - mae: 2.3753 - val_loss: 7.6430 - val_mae: 2.2984\n",
            "Epoch 48/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.0094 - mae: 2.3669 - val_loss: 7.6150 - val_mae: 2.2945\n",
            "Epoch 49/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9591 - mae: 2.3592 - val_loss: 7.5880 - val_mae: 2.2904\n",
            "Epoch 50/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9086 - mae: 2.3514 - val_loss: 7.5620 - val_mae: 2.2861\n",
            "Epoch 51/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8610 - mae: 2.3439 - val_loss: 7.5366 - val_mae: 2.2820\n",
            "Epoch 52/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8147 - mae: 2.3368 - val_loss: 7.5101 - val_mae: 2.2775\n",
            "Epoch 53/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.7667 - mae: 2.3289 - val_loss: 7.4841 - val_mae: 2.2735\n",
            "Epoch 54/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7212 - mae: 2.3220 - val_loss: 7.4588 - val_mae: 2.2693\n",
            "Epoch 55/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6733 - mae: 2.3141 - val_loss: 7.4337 - val_mae: 2.2652\n",
            "Epoch 56/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6276 - mae: 2.3073 - val_loss: 7.4120 - val_mae: 2.2611\n",
            "Epoch 57/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5830 - mae: 2.2996 - val_loss: 7.3901 - val_mae: 2.2567\n",
            "Epoch 58/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5373 - mae: 2.2919 - val_loss: 7.3662 - val_mae: 2.2520\n",
            "Epoch 59/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4916 - mae: 2.2841 - val_loss: 7.3440 - val_mae: 2.2473\n",
            "Epoch 60/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4475 - mae: 2.2762 - val_loss: 7.3245 - val_mae: 2.2431\n",
            "Epoch 61/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4025 - mae: 2.2685 - val_loss: 7.3040 - val_mae: 2.2389\n",
            "Epoch 62/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3596 - mae: 2.2610 - val_loss: 7.2843 - val_mae: 2.2353\n",
            "Epoch 63/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3160 - mae: 2.2533 - val_loss: 7.2668 - val_mae: 2.2318\n",
            "Epoch 64/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2724 - mae: 2.2459 - val_loss: 7.2503 - val_mae: 2.2284\n",
            "Epoch 65/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2300 - mae: 2.2381 - val_loss: 7.2331 - val_mae: 2.2255\n",
            "Epoch 66/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1870 - mae: 2.2302 - val_loss: 7.2158 - val_mae: 2.2218\n",
            "Epoch 67/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1437 - mae: 2.2222 - val_loss: 7.1980 - val_mae: 2.2189\n",
            "Epoch 68/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1030 - mae: 2.2141 - val_loss: 7.1859 - val_mae: 2.2161\n",
            "Epoch 69/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0602 - mae: 2.2062 - val_loss: 7.1669 - val_mae: 2.2126\n",
            "Epoch 70/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0197 - mae: 2.1981 - val_loss: 7.1580 - val_mae: 2.2105\n",
            "Epoch 71/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9786 - mae: 2.1905 - val_loss: 7.1408 - val_mae: 2.2070\n",
            "Epoch 72/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9378 - mae: 2.1825 - val_loss: 7.1304 - val_mae: 2.2045\n",
            "Epoch 73/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8963 - mae: 2.1740 - val_loss: 7.1160 - val_mae: 2.2013\n",
            "Epoch 74/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8563 - mae: 2.1658 - val_loss: 7.0997 - val_mae: 2.1978\n",
            "Epoch 75/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8160 - mae: 2.1580 - val_loss: 7.0888 - val_mae: 2.1951\n",
            "Epoch 76/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7769 - mae: 2.1504 - val_loss: 7.0675 - val_mae: 2.1908\n",
            "Epoch 77/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7394 - mae: 2.1423 - val_loss: 7.0586 - val_mae: 2.1888\n",
            "Epoch 78/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7036 - mae: 2.1354 - val_loss: 7.0416 - val_mae: 2.1851\n",
            "Epoch 79/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6688 - mae: 2.1279 - val_loss: 7.0255 - val_mae: 2.1825\n",
            "Epoch 80/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6354 - mae: 2.1211 - val_loss: 7.0090 - val_mae: 2.1793\n",
            "Epoch 81/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6018 - mae: 2.1145 - val_loss: 6.9947 - val_mae: 2.1763\n",
            "Epoch 82/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5706 - mae: 2.1082 - val_loss: 6.9775 - val_mae: 2.1731\n",
            "Epoch 83/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5384 - mae: 2.1022 - val_loss: 6.9589 - val_mae: 2.1687\n",
            "Epoch 84/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5042 - mae: 2.0947 - val_loss: 6.9462 - val_mae: 2.1664\n",
            "Epoch 85/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4757 - mae: 2.0894 - val_loss: 6.9304 - val_mae: 2.1625\n",
            "Epoch 86/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4422 - mae: 2.0831 - val_loss: 6.9140 - val_mae: 2.1594\n",
            "Epoch 87/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4131 - mae: 2.0773 - val_loss: 6.8943 - val_mae: 2.1549\n",
            "Epoch 88/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.3805 - mae: 2.0715 - val_loss: 6.8776 - val_mae: 2.1519\n",
            "Epoch 89/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3508 - mae: 2.0663 - val_loss: 6.8612 - val_mae: 2.1483\n",
            "Epoch 90/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3184 - mae: 2.0599 - val_loss: 6.8431 - val_mae: 2.1454\n",
            "Epoch 91/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.2919 - mae: 2.0545 - val_loss: 6.8260 - val_mae: 2.1428\n",
            "Epoch 92/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.2585 - mae: 2.0487 - val_loss: 6.8070 - val_mae: 2.1384\n",
            "Epoch 93/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.2306 - mae: 2.0425 - val_loss: 6.7941 - val_mae: 2.1367\n",
            "Epoch 94/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.1996 - mae: 2.0376 - val_loss: 6.7715 - val_mae: 2.1324\n",
            "Epoch 95/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 6.1704 - mae: 2.0317 - val_loss: 6.7565 - val_mae: 2.1303\n",
            "Epoch 96/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1391 - mae: 2.0266 - val_loss: 6.7364 - val_mae: 2.1266\n",
            "Epoch 97/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1100 - mae: 2.0214 - val_loss: 6.7170 - val_mae: 2.1223\n",
            "Epoch 98/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0800 - mae: 2.0153 - val_loss: 6.6990 - val_mae: 2.1202\n",
            "Epoch 99/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0543 - mae: 2.0114 - val_loss: 6.6827 - val_mae: 2.1167\n",
            "Epoch 100/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0248 - mae: 2.0065 - val_loss: 6.6644 - val_mae: 2.1137\n",
            "Epoch 101/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0019 - mae: 2.0026 - val_loss: 6.6465 - val_mae: 2.1095\n",
            "Epoch 102/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9704 - mae: 1.9968 - val_loss: 6.6338 - val_mae: 2.1071\n",
            "Epoch 103/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9456 - mae: 1.9929 - val_loss: 6.6134 - val_mae: 2.1030\n",
            "Epoch 104/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9173 - mae: 1.9876 - val_loss: 6.5996 - val_mae: 2.1002\n",
            "Epoch 105/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8940 - mae: 1.9841 - val_loss: 6.5859 - val_mae: 2.0968\n",
            "Epoch 106/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8674 - mae: 1.9787 - val_loss: 6.5669 - val_mae: 2.0935\n",
            "Epoch 107/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8434 - mae: 1.9752 - val_loss: 6.5486 - val_mae: 2.0898\n",
            "Epoch 108/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8179 - mae: 1.9702 - val_loss: 6.5350 - val_mae: 2.0864\n",
            "Epoch 109/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7927 - mae: 1.9659 - val_loss: 6.5200 - val_mae: 2.0841\n",
            "Epoch 110/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7653 - mae: 1.9619 - val_loss: 6.5057 - val_mae: 2.0811\n",
            "Epoch 111/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7446 - mae: 1.9583 - val_loss: 6.4879 - val_mae: 2.0770\n",
            "Epoch 112/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7139 - mae: 1.9525 - val_loss: 6.4764 - val_mae: 2.0752\n",
            "Epoch 113/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6899 - mae: 1.9497 - val_loss: 6.4610 - val_mae: 2.0719\n",
            "Epoch 114/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6662 - mae: 1.9452 - val_loss: 6.4447 - val_mae: 2.0682\n",
            "Epoch 115/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6404 - mae: 1.9404 - val_loss: 6.4312 - val_mae: 2.0654\n",
            "Epoch 116/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6131 - mae: 1.9361 - val_loss: 6.4145 - val_mae: 2.0631\n",
            "Epoch 117/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5930 - mae: 1.9325 - val_loss: 6.3991 - val_mae: 2.0592\n",
            "Epoch 118/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5676 - mae: 1.9269 - val_loss: 6.3915 - val_mae: 2.0578\n",
            "Epoch 119/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5416 - mae: 1.9234 - val_loss: 6.3740 - val_mae: 2.0546\n",
            "Epoch 120/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5179 - mae: 1.9182 - val_loss: 6.3621 - val_mae: 2.0515\n",
            "Epoch 121/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4929 - mae: 1.9137 - val_loss: 6.3492 - val_mae: 2.0495\n",
            "Epoch 122/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4700 - mae: 1.9097 - val_loss: 6.3347 - val_mae: 2.0463\n",
            "Epoch 123/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4450 - mae: 1.9047 - val_loss: 6.3180 - val_mae: 2.0436\n",
            "Epoch 124/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4238 - mae: 1.9007 - val_loss: 6.3048 - val_mae: 2.0403\n",
            "Epoch 125/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3981 - mae: 1.8958 - val_loss: 6.2914 - val_mae: 2.0373\n",
            "Epoch 126/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3744 - mae: 1.8909 - val_loss: 6.2722 - val_mae: 2.0337\n",
            "Epoch 127/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3495 - mae: 1.8862 - val_loss: 6.2586 - val_mae: 2.0294\n",
            "Epoch 128/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3239 - mae: 1.8814 - val_loss: 6.2444 - val_mae: 2.0261\n",
            "Epoch 129/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2997 - mae: 1.8767 - val_loss: 6.2249 - val_mae: 2.0219\n",
            "Epoch 130/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2725 - mae: 1.8719 - val_loss: 6.2210 - val_mae: 2.0200\n",
            "Epoch 131/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2534 - mae: 1.8675 - val_loss: 6.1925 - val_mae: 2.0141\n",
            "Epoch 132/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2277 - mae: 1.8629 - val_loss: 6.1909 - val_mae: 2.0130\n",
            "Epoch 133/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2070 - mae: 1.8589 - val_loss: 6.1668 - val_mae: 2.0070\n",
            "Epoch 134/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1819 - mae: 1.8544 - val_loss: 6.1576 - val_mae: 2.0047\n",
            "Epoch 135/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1624 - mae: 1.8495 - val_loss: 6.1375 - val_mae: 2.0007\n",
            "Epoch 136/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.1375 - mae: 1.8458 - val_loss: 6.1233 - val_mae: 1.9972\n",
            "Epoch 137/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.1168 - mae: 1.8409 - val_loss: 6.1059 - val_mae: 1.9930\n",
            "Epoch 138/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0903 - mae: 1.8358 - val_loss: 6.0966 - val_mae: 1.9913\n",
            "Epoch 139/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0706 - mae: 1.8319 - val_loss: 6.0760 - val_mae: 1.9872\n",
            "Epoch 140/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0478 - mae: 1.8269 - val_loss: 6.0744 - val_mae: 1.9857\n",
            "Epoch 141/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.0235 - mae: 1.8219 - val_loss: 6.0578 - val_mae: 1.9817\n",
            "Epoch 142/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0008 - mae: 1.8173 - val_loss: 6.0481 - val_mae: 1.9796\n",
            "Epoch 143/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9805 - mae: 1.8129 - val_loss: 6.0226 - val_mae: 1.9737\n",
            "Epoch 144/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9547 - mae: 1.8070 - val_loss: 6.0131 - val_mae: 1.9716\n",
            "Epoch 145/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9305 - mae: 1.8029 - val_loss: 6.0010 - val_mae: 1.9680\n",
            "Epoch 146/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9106 - mae: 1.7980 - val_loss: 5.9865 - val_mae: 1.9645\n",
            "Epoch 147/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8867 - mae: 1.7931 - val_loss: 5.9667 - val_mae: 1.9598\n",
            "Epoch 148/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8644 - mae: 1.7888 - val_loss: 5.9618 - val_mae: 1.9582\n",
            "Epoch 149/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8421 - mae: 1.7836 - val_loss: 5.9454 - val_mae: 1.9540\n",
            "Epoch 150/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8195 - mae: 1.7791 - val_loss: 5.9375 - val_mae: 1.9513\n",
            "Epoch 151/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7964 - mae: 1.7734 - val_loss: 5.9202 - val_mae: 1.9475\n",
            "Epoch 152/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7707 - mae: 1.7686 - val_loss: 5.9060 - val_mae: 1.9447\n",
            "Epoch 153/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7515 - mae: 1.7642 - val_loss: 5.8934 - val_mae: 1.9408\n",
            "Epoch 154/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7260 - mae: 1.7584 - val_loss: 5.8860 - val_mae: 1.9393\n",
            "Epoch 155/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7060 - mae: 1.7541 - val_loss: 5.8686 - val_mae: 1.9347\n",
            "Epoch 156/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6841 - mae: 1.7495 - val_loss: 5.8586 - val_mae: 1.9319\n",
            "Epoch 157/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6632 - mae: 1.7446 - val_loss: 5.8434 - val_mae: 1.9285\n",
            "Epoch 158/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.6393 - mae: 1.7392 - val_loss: 5.8369 - val_mae: 1.9263\n",
            "Epoch 159/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.6225 - mae: 1.7352 - val_loss: 5.8280 - val_mae: 1.9243\n",
            "Epoch 160/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5977 - mae: 1.7301 - val_loss: 5.8125 - val_mae: 1.9206\n",
            "Epoch 161/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5813 - mae: 1.7258 - val_loss: 5.7993 - val_mae: 1.9184\n",
            "Epoch 162/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5582 - mae: 1.7205 - val_loss: 5.7935 - val_mae: 1.9163\n",
            "Epoch 163/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5385 - mae: 1.7162 - val_loss: 5.7811 - val_mae: 1.9135\n",
            "Epoch 164/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5187 - mae: 1.7115 - val_loss: 5.7648 - val_mae: 1.9107\n",
            "Epoch 165/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5007 - mae: 1.7074 - val_loss: 5.7560 - val_mae: 1.9085\n",
            "Epoch 166/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4799 - mae: 1.7025 - val_loss: 5.7452 - val_mae: 1.9063\n",
            "Epoch 167/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4623 - mae: 1.6987 - val_loss: 5.7356 - val_mae: 1.9046\n",
            "Epoch 168/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4416 - mae: 1.6937 - val_loss: 5.7246 - val_mae: 1.9016\n",
            "Epoch 169/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4279 - mae: 1.6901 - val_loss: 5.7156 - val_mae: 1.9007\n",
            "Epoch 170/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4097 - mae: 1.6864 - val_loss: 5.7195 - val_mae: 1.9016\n",
            "Epoch 171/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3933 - mae: 1.6821 - val_loss: 5.7062 - val_mae: 1.8976\n",
            "Epoch 172/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3757 - mae: 1.6781 - val_loss: 5.7014 - val_mae: 1.8974\n",
            "Epoch 173/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3577 - mae: 1.6744 - val_loss: 5.6837 - val_mae: 1.8936\n",
            "Epoch 174/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3399 - mae: 1.6709 - val_loss: 5.6794 - val_mae: 1.8938\n",
            "Epoch 175/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3220 - mae: 1.6674 - val_loss: 5.6739 - val_mae: 1.8919\n",
            "Epoch 176/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.3044 - mae: 1.6632 - val_loss: 5.6574 - val_mae: 1.8896\n",
            "Epoch 177/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2886 - mae: 1.6603 - val_loss: 5.6560 - val_mae: 1.8896\n",
            "Epoch 178/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2724 - mae: 1.6567 - val_loss: 5.6372 - val_mae: 1.8857\n",
            "Epoch 179/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2540 - mae: 1.6535 - val_loss: 5.6314 - val_mae: 1.8854\n",
            "Epoch 180/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2375 - mae: 1.6499 - val_loss: 5.6224 - val_mae: 1.8830\n",
            "Epoch 181/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2205 - mae: 1.6453 - val_loss: 5.6142 - val_mae: 1.8839\n",
            "Epoch 182/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2086 - mae: 1.6434 - val_loss: 5.6033 - val_mae: 1.8801\n",
            "Epoch 183/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1871 - mae: 1.6387 - val_loss: 5.5973 - val_mae: 1.8814\n",
            "Epoch 184/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.1735 - mae: 1.6349 - val_loss: 5.5884 - val_mae: 1.8795\n",
            "Epoch 185/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.1589 - mae: 1.6324 - val_loss: 5.5800 - val_mae: 1.8780\n",
            "Epoch 186/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1415 - mae: 1.6285 - val_loss: 5.5703 - val_mae: 1.8765\n",
            "Epoch 187/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.1255 - mae: 1.6254 - val_loss: 5.5697 - val_mae: 1.8758\n",
            "Epoch 188/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.1127 - mae: 1.6219 - val_loss: 5.5510 - val_mae: 1.8732\n",
            "Epoch 189/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0964 - mae: 1.6195 - val_loss: 5.5465 - val_mae: 1.8711\n",
            "Epoch 190/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0789 - mae: 1.6151 - val_loss: 5.5398 - val_mae: 1.8712\n",
            "Epoch 191/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0652 - mae: 1.6117 - val_loss: 5.5386 - val_mae: 1.8712\n",
            "Epoch 192/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0511 - mae: 1.6091 - val_loss: 5.5237 - val_mae: 1.8667\n",
            "Epoch 193/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0337 - mae: 1.6057 - val_loss: 5.5035 - val_mae: 1.8629\n",
            "Epoch 194/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0188 - mae: 1.6027 - val_loss: 5.5020 - val_mae: 1.8630\n",
            "Epoch 195/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0024 - mae: 1.5987 - val_loss: 5.4920 - val_mae: 1.8617\n",
            "Epoch 196/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9865 - mae: 1.5956 - val_loss: 5.4816 - val_mae: 1.8584\n",
            "Epoch 197/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9699 - mae: 1.5912 - val_loss: 5.4650 - val_mae: 1.8582\n",
            "Epoch 198/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9553 - mae: 1.5883 - val_loss: 5.4589 - val_mae: 1.8566\n",
            "Epoch 199/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9399 - mae: 1.5854 - val_loss: 5.4455 - val_mae: 1.8541\n",
            "Epoch 200/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9219 - mae: 1.5809 - val_loss: 5.4387 - val_mae: 1.8533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "y_pred = rnn_model.predict(X_test_rnn)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"R² Score: {r2}\")\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"MAE: {mae}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8izL-9l1syx7",
        "outputId": "42d6b16d-4994-4c6d-c22d-ebcd4df80ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f3c6fe739c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "R² Score: 0.39223327364900895\n",
            "MSE: 5.4387086787119\n",
            "RMSE: 2.332103916790995\n",
            "MAE: 1.8533093983762694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf, numpy as np, random, os\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n"
      ],
      "metadata": {
        "id": "A-WUWSP7vEWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n"
      ],
      "metadata": {
        "id": "QlFjnfecvGd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf, numpy as np, random, os\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n"
      ],
      "metadata": {
        "id": "1Vnd-IBnvyOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n"
      ],
      "metadata": {
        "id": "kLlJsO99w6ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "model.fit(X_train_rnn, y_train, validation_data=(X_test_rnn, y_test), epochs=200, callbacks=[es])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "uee2avARw8RF",
        "outputId": "fd776e9d-c675-4cdf-b466-d6ee203ea4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2483807487.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM\n",
        "\n",
        "# Example RNN Model\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(64, activation='tanh', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))  # regression output\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsNKDUpZxN-F",
        "outputId": "2e5a87f5-6707-4ae4-94b4-866e797fdcde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_rnn, y_train,\n",
        "    validation_data=(X_test_rnn, y_test),\n",
        "    epochs=200,\n",
        "    callbacks=[es],\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uow1XlTdxQRs",
        "outputId": "22ee4764-a37c-46b5-f8c3-e930b4164844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 675.5500 - mae: 25.7985 - val_loss: 630.8401 - val_mae: 24.9399\n",
            "Epoch 2/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 635.5869 - mae: 25.0124 - val_loss: 594.1142 - val_mae: 24.1898\n",
            "Epoch 3/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 598.7742 - mae: 24.2616 - val_loss: 550.7097 - val_mae: 23.2701\n",
            "Epoch 4/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 552.5092 - mae: 23.2803 - val_loss: 493.7808 - val_mae: 21.9996\n",
            "Epoch 5/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 491.9816 - mae: 21.9229 - val_loss: 420.9966 - val_mae: 20.2500\n",
            "Epoch 6/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 415.5284 - mae: 20.0659 - val_loss: 333.4238 - val_mae: 17.9069\n",
            "Epoch 7/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 325.4215 - mae: 17.6097 - val_loss: 237.8014 - val_mae: 14.9227\n",
            "Epoch 8/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 229.5388 - mae: 14.5290 - val_loss: 147.1060 - val_mae: 11.4036\n",
            "Epoch 9/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 140.5031 - mae: 10.9573 - val_loss: 75.5272 - val_mae: 7.7661\n",
            "Epoch 10/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 71.5400 - mae: 7.3087 - val_loss: 31.6900 - val_mae: 4.6312\n",
            "Epoch 11/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 30.5058 - mae: 4.4230 - val_loss: 14.4527 - val_mae: 2.9999\n",
            "Epoch 12/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 15.1715 - mae: 3.1432 - val_loss: 11.1729 - val_mae: 2.6794\n",
            "Epoch 13/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 12.0948 - mae: 2.8319 - val_loss: 10.7091 - val_mae: 2.6338\n",
            "Epoch 14/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.4582 - mae: 2.7610 - val_loss: 10.3515 - val_mae: 2.6016\n",
            "Epoch 15/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.1084 - mae: 2.7299 - val_loss: 10.0194 - val_mae: 2.5702\n",
            "Epoch 16/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.8305 - mae: 2.7085 - val_loss: 9.7500 - val_mae: 2.5458\n",
            "Epoch 17/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 10.5928 - mae: 2.6906 - val_loss: 9.5391 - val_mae: 2.5267\n",
            "Epoch 18/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.3850 - mae: 2.6728 - val_loss: 9.3652 - val_mae: 2.5117\n",
            "Epoch 19/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.2089 - mae: 2.6570 - val_loss: 9.2240 - val_mae: 2.4999\n",
            "Epoch 20/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.0617 - mae: 2.6432 - val_loss: 9.1090 - val_mae: 2.4897\n",
            "Epoch 21/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9331 - mae: 2.6308 - val_loss: 9.0095 - val_mae: 2.4817\n",
            "Epoch 22/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8201 - mae: 2.6189 - val_loss: 8.9113 - val_mae: 2.4725\n",
            "Epoch 23/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7210 - mae: 2.6080 - val_loss: 8.8249 - val_mae: 2.4630\n",
            "Epoch 24/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6254 - mae: 2.5979 - val_loss: 8.7418 - val_mae: 2.4532\n",
            "Epoch 25/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5344 - mae: 2.5870 - val_loss: 8.6646 - val_mae: 2.4439\n",
            "Epoch 26/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4481 - mae: 2.5761 - val_loss: 8.5941 - val_mae: 2.4351\n",
            "Epoch 27/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3660 - mae: 2.5663 - val_loss: 8.5275 - val_mae: 2.4265\n",
            "Epoch 28/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2852 - mae: 2.5563 - val_loss: 8.4673 - val_mae: 2.4182\n",
            "Epoch 29/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.2074 - mae: 2.5462 - val_loss: 8.4094 - val_mae: 2.4100\n",
            "Epoch 30/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1317 - mae: 2.5359 - val_loss: 8.3556 - val_mae: 2.4020\n",
            "Epoch 31/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0566 - mae: 2.5254 - val_loss: 8.2979 - val_mae: 2.3934\n",
            "Epoch 32/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9821 - mae: 2.5146 - val_loss: 8.2418 - val_mae: 2.3853\n",
            "Epoch 33/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9108 - mae: 2.5041 - val_loss: 8.1881 - val_mae: 2.3777\n",
            "Epoch 34/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8425 - mae: 2.4939 - val_loss: 8.1401 - val_mae: 2.3711\n",
            "Epoch 35/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7732 - mae: 2.4835 - val_loss: 8.0925 - val_mae: 2.3646\n",
            "Epoch 36/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7070 - mae: 2.4730 - val_loss: 8.0456 - val_mae: 2.3580\n",
            "Epoch 37/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6431 - mae: 2.4625 - val_loss: 8.0022 - val_mae: 2.3515\n",
            "Epoch 38/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5784 - mae: 2.4529 - val_loss: 7.9609 - val_mae: 2.3455\n",
            "Epoch 39/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.5151 - mae: 2.4427 - val_loss: 7.9154 - val_mae: 2.3387\n",
            "Epoch 40/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4539 - mae: 2.4337 - val_loss: 7.8772 - val_mae: 2.3328\n",
            "Epoch 41/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3927 - mae: 2.4247 - val_loss: 7.8385 - val_mae: 2.3271\n",
            "Epoch 42/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3353 - mae: 2.4163 - val_loss: 7.7997 - val_mae: 2.3211\n",
            "Epoch 43/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2780 - mae: 2.4082 - val_loss: 7.7649 - val_mae: 2.3160\n",
            "Epoch 44/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.2235 - mae: 2.4000 - val_loss: 7.7329 - val_mae: 2.3111\n",
            "Epoch 45/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.1669 - mae: 2.3914 - val_loss: 7.7003 - val_mae: 2.3066\n",
            "Epoch 46/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.1163 - mae: 2.3836 - val_loss: 7.6720 - val_mae: 2.3029\n",
            "Epoch 47/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.0607 - mae: 2.3753 - val_loss: 7.6430 - val_mae: 2.2984\n",
            "Epoch 48/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.0094 - mae: 2.3669 - val_loss: 7.6150 - val_mae: 2.2945\n",
            "Epoch 49/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9591 - mae: 2.3592 - val_loss: 7.5880 - val_mae: 2.2904\n",
            "Epoch 50/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9086 - mae: 2.3514 - val_loss: 7.5620 - val_mae: 2.2861\n",
            "Epoch 51/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8610 - mae: 2.3439 - val_loss: 7.5366 - val_mae: 2.2820\n",
            "Epoch 52/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8147 - mae: 2.3368 - val_loss: 7.5101 - val_mae: 2.2775\n",
            "Epoch 53/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7667 - mae: 2.3289 - val_loss: 7.4841 - val_mae: 2.2735\n",
            "Epoch 54/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7212 - mae: 2.3220 - val_loss: 7.4588 - val_mae: 2.2693\n",
            "Epoch 55/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6733 - mae: 2.3141 - val_loss: 7.4337 - val_mae: 2.2652\n",
            "Epoch 56/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6276 - mae: 2.3073 - val_loss: 7.4120 - val_mae: 2.2611\n",
            "Epoch 57/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5830 - mae: 2.2996 - val_loss: 7.3901 - val_mae: 2.2567\n",
            "Epoch 58/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5373 - mae: 2.2919 - val_loss: 7.3662 - val_mae: 2.2520\n",
            "Epoch 59/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4916 - mae: 2.2841 - val_loss: 7.3440 - val_mae: 2.2473\n",
            "Epoch 60/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4475 - mae: 2.2762 - val_loss: 7.3245 - val_mae: 2.2431\n",
            "Epoch 61/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.4025 - mae: 2.2685 - val_loss: 7.3040 - val_mae: 2.2389\n",
            "Epoch 62/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3596 - mae: 2.2610 - val_loss: 7.2843 - val_mae: 2.2353\n",
            "Epoch 63/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3160 - mae: 2.2533 - val_loss: 7.2668 - val_mae: 2.2318\n",
            "Epoch 64/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2724 - mae: 2.2459 - val_loss: 7.2503 - val_mae: 2.2284\n",
            "Epoch 65/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2300 - mae: 2.2381 - val_loss: 7.2331 - val_mae: 2.2255\n",
            "Epoch 66/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1870 - mae: 2.2302 - val_loss: 7.2158 - val_mae: 2.2218\n",
            "Epoch 67/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1437 - mae: 2.2222 - val_loss: 7.1980 - val_mae: 2.2189\n",
            "Epoch 68/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1030 - mae: 2.2141 - val_loss: 7.1859 - val_mae: 2.2161\n",
            "Epoch 69/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0602 - mae: 2.2062 - val_loss: 7.1669 - val_mae: 2.2126\n",
            "Epoch 70/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0197 - mae: 2.1981 - val_loss: 7.1580 - val_mae: 2.2105\n",
            "Epoch 71/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9786 - mae: 2.1905 - val_loss: 7.1408 - val_mae: 2.2070\n",
            "Epoch 72/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9378 - mae: 2.1825 - val_loss: 7.1304 - val_mae: 2.2045\n",
            "Epoch 73/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8963 - mae: 2.1740 - val_loss: 7.1160 - val_mae: 2.2013\n",
            "Epoch 74/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8563 - mae: 2.1658 - val_loss: 7.0997 - val_mae: 2.1978\n",
            "Epoch 75/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8160 - mae: 2.1580 - val_loss: 7.0888 - val_mae: 2.1951\n",
            "Epoch 76/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7769 - mae: 2.1504 - val_loss: 7.0675 - val_mae: 2.1908\n",
            "Epoch 77/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7394 - mae: 2.1423 - val_loss: 7.0586 - val_mae: 2.1888\n",
            "Epoch 78/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7036 - mae: 2.1354 - val_loss: 7.0416 - val_mae: 2.1851\n",
            "Epoch 79/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6688 - mae: 2.1279 - val_loss: 7.0255 - val_mae: 2.1825\n",
            "Epoch 80/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6354 - mae: 2.1211 - val_loss: 7.0090 - val_mae: 2.1793\n",
            "Epoch 81/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6018 - mae: 2.1145 - val_loss: 6.9947 - val_mae: 2.1763\n",
            "Epoch 82/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5706 - mae: 2.1082 - val_loss: 6.9775 - val_mae: 2.1731\n",
            "Epoch 83/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5384 - mae: 2.1022 - val_loss: 6.9589 - val_mae: 2.1687\n",
            "Epoch 84/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5042 - mae: 2.0947 - val_loss: 6.9462 - val_mae: 2.1664\n",
            "Epoch 85/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4757 - mae: 2.0894 - val_loss: 6.9304 - val_mae: 2.1625\n",
            "Epoch 86/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4422 - mae: 2.0831 - val_loss: 6.9140 - val_mae: 2.1594\n",
            "Epoch 87/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4131 - mae: 2.0773 - val_loss: 6.8943 - val_mae: 2.1549\n",
            "Epoch 88/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.3805 - mae: 2.0715 - val_loss: 6.8776 - val_mae: 2.1519\n",
            "Epoch 89/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.3508 - mae: 2.0663 - val_loss: 6.8612 - val_mae: 2.1483\n",
            "Epoch 90/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.3184 - mae: 2.0599 - val_loss: 6.8431 - val_mae: 2.1454\n",
            "Epoch 91/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.2919 - mae: 2.0545 - val_loss: 6.8260 - val_mae: 2.1428\n",
            "Epoch 92/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2585 - mae: 2.0487 - val_loss: 6.8070 - val_mae: 2.1384\n",
            "Epoch 93/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2306 - mae: 2.0425 - val_loss: 6.7941 - val_mae: 2.1367\n",
            "Epoch 94/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1996 - mae: 2.0376 - val_loss: 6.7715 - val_mae: 2.1324\n",
            "Epoch 95/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1704 - mae: 2.0317 - val_loss: 6.7565 - val_mae: 2.1303\n",
            "Epoch 96/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1391 - mae: 2.0266 - val_loss: 6.7364 - val_mae: 2.1266\n",
            "Epoch 97/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1100 - mae: 2.0214 - val_loss: 6.7170 - val_mae: 2.1223\n",
            "Epoch 98/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0800 - mae: 2.0153 - val_loss: 6.6990 - val_mae: 2.1202\n",
            "Epoch 99/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0543 - mae: 2.0114 - val_loss: 6.6827 - val_mae: 2.1167\n",
            "Epoch 100/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0248 - mae: 2.0065 - val_loss: 6.6644 - val_mae: 2.1137\n",
            "Epoch 101/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.0019 - mae: 2.0026 - val_loss: 6.6465 - val_mae: 2.1095\n",
            "Epoch 102/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9704 - mae: 1.9968 - val_loss: 6.6338 - val_mae: 2.1071\n",
            "Epoch 103/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9456 - mae: 1.9929 - val_loss: 6.6134 - val_mae: 2.1030\n",
            "Epoch 104/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9173 - mae: 1.9876 - val_loss: 6.5996 - val_mae: 2.1002\n",
            "Epoch 105/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8940 - mae: 1.9841 - val_loss: 6.5859 - val_mae: 2.0968\n",
            "Epoch 106/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8674 - mae: 1.9787 - val_loss: 6.5669 - val_mae: 2.0935\n",
            "Epoch 107/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.8434 - mae: 1.9752 - val_loss: 6.5486 - val_mae: 2.0898\n",
            "Epoch 108/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8179 - mae: 1.9702 - val_loss: 6.5350 - val_mae: 2.0864\n",
            "Epoch 109/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7927 - mae: 1.9659 - val_loss: 6.5200 - val_mae: 2.0841\n",
            "Epoch 110/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7653 - mae: 1.9619 - val_loss: 6.5057 - val_mae: 2.0811\n",
            "Epoch 111/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7446 - mae: 1.9583 - val_loss: 6.4879 - val_mae: 2.0770\n",
            "Epoch 112/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7139 - mae: 1.9525 - val_loss: 6.4764 - val_mae: 2.0752\n",
            "Epoch 113/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6899 - mae: 1.9497 - val_loss: 6.4610 - val_mae: 2.0719\n",
            "Epoch 114/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6662 - mae: 1.9452 - val_loss: 6.4447 - val_mae: 2.0682\n",
            "Epoch 115/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6404 - mae: 1.9404 - val_loss: 6.4312 - val_mae: 2.0654\n",
            "Epoch 116/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6131 - mae: 1.9361 - val_loss: 6.4145 - val_mae: 2.0631\n",
            "Epoch 117/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5930 - mae: 1.9325 - val_loss: 6.3991 - val_mae: 2.0592\n",
            "Epoch 118/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5676 - mae: 1.9269 - val_loss: 6.3915 - val_mae: 2.0578\n",
            "Epoch 119/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5416 - mae: 1.9234 - val_loss: 6.3740 - val_mae: 2.0546\n",
            "Epoch 120/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5179 - mae: 1.9182 - val_loss: 6.3621 - val_mae: 2.0515\n",
            "Epoch 121/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4929 - mae: 1.9137 - val_loss: 6.3492 - val_mae: 2.0495\n",
            "Epoch 122/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4700 - mae: 1.9097 - val_loss: 6.3347 - val_mae: 2.0463\n",
            "Epoch 123/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4450 - mae: 1.9047 - val_loss: 6.3180 - val_mae: 2.0436\n",
            "Epoch 124/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4238 - mae: 1.9007 - val_loss: 6.3048 - val_mae: 2.0403\n",
            "Epoch 125/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3981 - mae: 1.8958 - val_loss: 6.2914 - val_mae: 2.0373\n",
            "Epoch 126/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3744 - mae: 1.8909 - val_loss: 6.2722 - val_mae: 2.0337\n",
            "Epoch 127/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3495 - mae: 1.8862 - val_loss: 6.2586 - val_mae: 2.0294\n",
            "Epoch 128/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3239 - mae: 1.8814 - val_loss: 6.2444 - val_mae: 2.0261\n",
            "Epoch 129/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2997 - mae: 1.8767 - val_loss: 6.2249 - val_mae: 2.0219\n",
            "Epoch 130/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2725 - mae: 1.8719 - val_loss: 6.2210 - val_mae: 2.0200\n",
            "Epoch 131/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2534 - mae: 1.8675 - val_loss: 6.1925 - val_mae: 2.0141\n",
            "Epoch 132/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2277 - mae: 1.8629 - val_loss: 6.1909 - val_mae: 2.0130\n",
            "Epoch 133/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.2070 - mae: 1.8589 - val_loss: 6.1668 - val_mae: 2.0070\n",
            "Epoch 134/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1819 - mae: 1.8544 - val_loss: 6.1576 - val_mae: 2.0047\n",
            "Epoch 135/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.1624 - mae: 1.8495 - val_loss: 6.1375 - val_mae: 2.0007\n",
            "Epoch 136/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.1375 - mae: 1.8458 - val_loss: 6.1233 - val_mae: 1.9972\n",
            "Epoch 137/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.1168 - mae: 1.8409 - val_loss: 6.1059 - val_mae: 1.9930\n",
            "Epoch 138/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.0903 - mae: 1.8358 - val_loss: 6.0966 - val_mae: 1.9913\n",
            "Epoch 139/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.0706 - mae: 1.8319 - val_loss: 6.0760 - val_mae: 1.9872\n",
            "Epoch 140/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0478 - mae: 1.8269 - val_loss: 6.0744 - val_mae: 1.9857\n",
            "Epoch 141/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0235 - mae: 1.8219 - val_loss: 6.0578 - val_mae: 1.9817\n",
            "Epoch 142/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0008 - mae: 1.8173 - val_loss: 6.0481 - val_mae: 1.9796\n",
            "Epoch 143/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9805 - mae: 1.8129 - val_loss: 6.0226 - val_mae: 1.9737\n",
            "Epoch 144/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9547 - mae: 1.8070 - val_loss: 6.0131 - val_mae: 1.9716\n",
            "Epoch 145/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.9305 - mae: 1.8029 - val_loss: 6.0010 - val_mae: 1.9680\n",
            "Epoch 146/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9106 - mae: 1.7980 - val_loss: 5.9865 - val_mae: 1.9645\n",
            "Epoch 147/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8867 - mae: 1.7931 - val_loss: 5.9667 - val_mae: 1.9598\n",
            "Epoch 148/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8644 - mae: 1.7888 - val_loss: 5.9618 - val_mae: 1.9582\n",
            "Epoch 149/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8421 - mae: 1.7836 - val_loss: 5.9454 - val_mae: 1.9540\n",
            "Epoch 150/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8195 - mae: 1.7791 - val_loss: 5.9375 - val_mae: 1.9513\n",
            "Epoch 151/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.7964 - mae: 1.7734 - val_loss: 5.9202 - val_mae: 1.9475\n",
            "Epoch 152/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7707 - mae: 1.7686 - val_loss: 5.9060 - val_mae: 1.9447\n",
            "Epoch 153/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7515 - mae: 1.7642 - val_loss: 5.8934 - val_mae: 1.9408\n",
            "Epoch 154/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7260 - mae: 1.7584 - val_loss: 5.8860 - val_mae: 1.9393\n",
            "Epoch 155/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7060 - mae: 1.7541 - val_loss: 5.8686 - val_mae: 1.9347\n",
            "Epoch 156/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6841 - mae: 1.7495 - val_loss: 5.8586 - val_mae: 1.9319\n",
            "Epoch 157/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6632 - mae: 1.7446 - val_loss: 5.8434 - val_mae: 1.9285\n",
            "Epoch 158/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6393 - mae: 1.7392 - val_loss: 5.8369 - val_mae: 1.9263\n",
            "Epoch 159/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6225 - mae: 1.7352 - val_loss: 5.8280 - val_mae: 1.9243\n",
            "Epoch 160/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5977 - mae: 1.7301 - val_loss: 5.8125 - val_mae: 1.9206\n",
            "Epoch 161/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5813 - mae: 1.7258 - val_loss: 5.7993 - val_mae: 1.9184\n",
            "Epoch 162/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5582 - mae: 1.7205 - val_loss: 5.7935 - val_mae: 1.9163\n",
            "Epoch 163/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5385 - mae: 1.7162 - val_loss: 5.7811 - val_mae: 1.9135\n",
            "Epoch 164/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.5187 - mae: 1.7115 - val_loss: 5.7648 - val_mae: 1.9107\n",
            "Epoch 165/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5007 - mae: 1.7074 - val_loss: 5.7560 - val_mae: 1.9085\n",
            "Epoch 166/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4799 - mae: 1.7025 - val_loss: 5.7452 - val_mae: 1.9063\n",
            "Epoch 167/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4623 - mae: 1.6987 - val_loss: 5.7356 - val_mae: 1.9046\n",
            "Epoch 168/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4416 - mae: 1.6937 - val_loss: 5.7246 - val_mae: 1.9016\n",
            "Epoch 169/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4279 - mae: 1.6901 - val_loss: 5.7156 - val_mae: 1.9007\n",
            "Epoch 170/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4097 - mae: 1.6864 - val_loss: 5.7195 - val_mae: 1.9016\n",
            "Epoch 171/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3933 - mae: 1.6821 - val_loss: 5.7062 - val_mae: 1.8976\n",
            "Epoch 172/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3757 - mae: 1.6781 - val_loss: 5.7014 - val_mae: 1.8974\n",
            "Epoch 173/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3577 - mae: 1.6744 - val_loss: 5.6837 - val_mae: 1.8936\n",
            "Epoch 174/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3399 - mae: 1.6709 - val_loss: 5.6794 - val_mae: 1.8938\n",
            "Epoch 175/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.3220 - mae: 1.6674 - val_loss: 5.6739 - val_mae: 1.8919\n",
            "Epoch 176/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.3044 - mae: 1.6632 - val_loss: 5.6574 - val_mae: 1.8896\n",
            "Epoch 177/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.2886 - mae: 1.6603 - val_loss: 5.6560 - val_mae: 1.8896\n",
            "Epoch 178/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.2724 - mae: 1.6567 - val_loss: 5.6372 - val_mae: 1.8857\n",
            "Epoch 179/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.2540 - mae: 1.6535 - val_loss: 5.6314 - val_mae: 1.8854\n",
            "Epoch 180/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.2375 - mae: 1.6499 - val_loss: 5.6224 - val_mae: 1.8830\n",
            "Epoch 181/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2205 - mae: 1.6453 - val_loss: 5.6142 - val_mae: 1.8839\n",
            "Epoch 182/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2086 - mae: 1.6434 - val_loss: 5.6033 - val_mae: 1.8801\n",
            "Epoch 183/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1871 - mae: 1.6387 - val_loss: 5.5973 - val_mae: 1.8814\n",
            "Epoch 184/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1735 - mae: 1.6349 - val_loss: 5.5884 - val_mae: 1.8795\n",
            "Epoch 185/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1589 - mae: 1.6324 - val_loss: 5.5800 - val_mae: 1.8780\n",
            "Epoch 186/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1415 - mae: 1.6285 - val_loss: 5.5703 - val_mae: 1.8765\n",
            "Epoch 187/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1255 - mae: 1.6254 - val_loss: 5.5697 - val_mae: 1.8758\n",
            "Epoch 188/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1127 - mae: 1.6219 - val_loss: 5.5510 - val_mae: 1.8732\n",
            "Epoch 189/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0964 - mae: 1.6195 - val_loss: 5.5465 - val_mae: 1.8711\n",
            "Epoch 190/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0789 - mae: 1.6151 - val_loss: 5.5398 - val_mae: 1.8712\n",
            "Epoch 191/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0652 - mae: 1.6117 - val_loss: 5.5386 - val_mae: 1.8712\n",
            "Epoch 192/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0511 - mae: 1.6091 - val_loss: 5.5237 - val_mae: 1.8667\n",
            "Epoch 193/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0337 - mae: 1.6057 - val_loss: 5.5035 - val_mae: 1.8629\n",
            "Epoch 194/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0188 - mae: 1.6027 - val_loss: 5.5020 - val_mae: 1.8630\n",
            "Epoch 195/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0024 - mae: 1.5987 - val_loss: 5.4920 - val_mae: 1.8617\n",
            "Epoch 196/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9865 - mae: 1.5956 - val_loss: 5.4816 - val_mae: 1.8584\n",
            "Epoch 197/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9699 - mae: 1.5912 - val_loss: 5.4650 - val_mae: 1.8582\n",
            "Epoch 198/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.9553 - mae: 1.5883 - val_loss: 5.4589 - val_mae: 1.8566\n",
            "Epoch 199/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9399 - mae: 1.5854 - val_loss: 5.4455 - val_mae: 1.8541\n",
            "Epoch 200/200\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9219 - mae: 1.5809 - val_loss: 5.4387 - val_mae: 1.8533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "y_pred = model.predict(X_test_rnn)\n",
        "\n",
        "print(\"R²:\", r2_score(y_test, y_pred))\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPvA9b5Vxi3v",
        "outputId": "537beb51-e72d-4825-9ff5-6b87cf4beaac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "R²: 0.39223327364900895\n",
            "MSE: 5.4387086787119\n",
            "MAE: 1.8533093983762694\n"
          ]
        }
      ]
    }
  ]
}